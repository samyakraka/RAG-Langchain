{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkci3pXEtVTG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EZFBGOBt1Oe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Set the API key from environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR_MPVnJuVla"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"/content/Healthcare_Guide_Proper.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbjTwtBTvlpP"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n",
        "# 4. Create embeddings using Gemini\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNhqDahZvsrL"
      },
      "outputs": [],
      "source": [
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# 6. Create QA chain using Gemini Pro\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\"),\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdJUwEe3v-aI",
        "outputId": "3436c16b-8163-4e53-d7ee-66810f7f129c"
      },
      "outputs": [],
      "source": [
        "\n",
        "while True:\n",
        "    query = input(\"\\nAsk your question (or type 'exit'): \")\n",
        "    if query.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    result = qa_chain(query)\n",
        "    print(\"\\nüîç Answer:\\n\", result[\"result\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
