{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mkci3pXEtVTG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1EZFBGOBt1Oe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Set the API key from environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lR_MPVnJuVla"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"content/Healthcare_Guide_Proper.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dbjTwtBTvlpP"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n",
        "# 4. Create embeddings using Gemini\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VNhqDahZvsrL"
      },
      "outputs": [],
      "source": [
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# 6. Create QA chain using Gemini Pro\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\"),\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdJUwEe3v-aI",
        "outputId": "3436c16b-8163-4e53-d7ee-66810f7f129c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3s/cr7b3j3j1rj368kp_24dj_k40000gn/T/ipykernel_2121/2999498574.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain(query)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Answer:\n",
            " Hello! How can I help you today with information about healthcare?\n",
            "\n",
            "üîç Answer:\n",
            " The document is a Healthcare Information Guide that provides tips and advice on maintaining good health, including the importance of regular check-ups, nutrition, exercise, mental health, preventive measures, and healthcare access.\n",
            "\n",
            "üîç Answer:\n",
            " The document is a Healthcare Information Guide that provides tips and advice on maintaining good health, including the importance of regular check-ups, nutrition, exercise, mental health, preventive measures, and healthcare access.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "while True:\n",
        "    query = input(\"\\nAsk your question (or type 'exit'): \")\n",
        "    if query.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    result = qa_chain(query)\n",
        "    print(\"\\nüîç Answer:\\n\", result[\"result\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
